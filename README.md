ğŸ§  TP Spark SQL â€” Analyse des incidents dâ€™une entreprise industrielle
Ce projet vise Ã  dÃ©montrer comment exploiter Apache Spark SQL avec Java pour analyser des donnÃ©es liÃ©es aux incidents survenus dans une entreprise industrielle. Lâ€™application est conÃ§ue pour Ãªtre testÃ©e en local, puis facilement dÃ©ployÃ©e sur un cluster Spark via Docker.

ğŸ“‹ Contexte de l'exercice
Objectif : crÃ©er une application Spark capable de traiter un fichier CSV nommÃ© incidents.csv, regroupant les incidents dÃ©clarÃ©s dans diffÃ©rents services de lâ€™entreprise.

Lâ€™application devra permettre :

De compter le nombre total dâ€™incidents par service.

Dâ€™identifier les deux annÃ©es au cours desquelles le plus grand nombre dâ€™incidents a Ã©tÃ© enregistrÃ©.

Exemple de contenu du fichier CSV :

python-repl
Copier
Modifier
Id,titre,description,service,date
1,Panne serveur,Serveur crashÃ©,IT,2023-03-15
2,Fuite d'eau,Canalisation percÃ©e,Maintenance,2022-06-20
3,Erreur SAP,Transaction Ã©chouÃ©e,IT,2023-08-09
...
ğŸ“ Organisation du projet
css
Copier
Modifier
TP_SparkSQL/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ main/java/ServiceIncidents.java
â”œâ”€â”€ incidents.csv
â”œâ”€â”€ pom.xml
âš™ï¸ Technologies utilisÃ©es
Java (version 11 ou supÃ©rieure)

Apache Spark 3.5.5

Spark SQL

Maven

ğŸ“¸ RÃ©sultats attendus
L'application doit produire en sortie :

Le nombre dâ€™incidents enregistrÃ©s pour chaque service (IT, Maintenance, etc.)

Les deux annÃ©es les plus touchÃ©es par les incidents

Ces rÃ©sultats seront affichÃ©s directement dans le terminal.

âœï¸ RÃ©alisÃ© par
Dalal Benallou
Travail pratique de Big Data â€” Spark SQL
Mai 2025
